{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Project-Digital-Classification-SVHN-Thiru.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jpthirumalai/aiml/blob/master/Project_Digital_Classification_SVHN_Thiru.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfajwoeBcnke",
        "colab_type": "code",
        "outputId": "545a99b4-789b-4992-8e85-422fd3b6b8a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYoOHQYiiJYw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "projfolder = '/content/drive/My Drive/AIML/AI/NNProject/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlV2rWPhcnki",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "#tf.reset_default_graph()\n",
        "#tf.compat.v1.disable_eager_execution()\n",
        "import h5py\n",
        "file=projfolder+'SVHN_single_grey1.h5'\n",
        "f= h5py.File(file,'r')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWoGQa4GtxBl",
        "colab_type": "text"
      },
      "source": [
        "##Step 1: Load Train and Test data from .h5 file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGKxUcpjcnkl",
        "colab_type": "code",
        "outputId": "89500125-db40-408f-e0ab-f6c25cfdcccb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Load the X_train, X_test, Y_train, Y_test, X_val and Y_val datasets from the h5py file\t2\n",
        "list(f.keys())\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['X_test', 'X_train', 'X_val', 'y_test', 'y_train', 'y_val']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qX0wr1sIwqTP",
        "colab_type": "code",
        "outputId": "e7bb0f09-aacb-4d06-992b-469a3498c1ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "for key in list(f.keys()):\n",
        "  print('Shape of '+key+':'+str(f[key].shape))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of X_test:(18000, 32, 32)\n",
            "Shape of X_train:(42000, 32, 32)\n",
            "Shape of X_val:(60000, 32, 32)\n",
            "Shape of y_test:(18000,)\n",
            "Shape of y_train:(42000,)\n",
            "Shape of y_val:(60000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxKK6TwvzJcp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test = f['X_test']\n",
        "X_train = f['X_train']\n",
        "X_val = f['X_val']\n",
        "y_test = f['y_test']\n",
        "y_train = f['y_train']\n",
        "y_val = f['y_val']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05F3bRkJt-VX",
        "colab_type": "text"
      },
      "source": [
        "## Step 2: Flatten the images for Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyklvqQzpShO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "f4aeb306-2c8c-44ca-d851-4ef5a7463943"
      },
      "source": [
        " #Flatten the images for Keras\t2\n",
        " X_test.reshape(18000,1024)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-82-94e9ca8fabac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m18000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'Dataset' object has no attribute 'reshape'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79D6mV2Nlnzj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "c9ab5d77-a01f-45ef-c62a-a2ef83e7e4a9"
      },
      "source": [
        "# through thies error AttributeError: 'Dataset' object has no attribute 'reshape', need to convert to numpy array\n",
        "X_test = np.array(X_test)\n",
        "print('before converting',X_test.shape)\n",
        "X_test = X_test.reshape(18000,1024)\n",
        "print('after converting Test Size',X_test.shape)\n",
        "#similarly convert required dataset to numpy array and reshape 32X32 into 1024\n",
        "X_train = np.array(X_train).reshape(42000,1024)\n",
        "\n",
        "print('after converting Train Size',X_train.shape)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "before converting (18000, 32, 32)\n",
            "after converting Test Size (18000, 1024)\n",
            "after converting Train Size (42000, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Teh5EKALuFTw",
        "colab_type": "text"
      },
      "source": [
        "### Verifying the image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYF2yjE_cnkp",
        "colab_type": "code",
        "outputId": "9f4b3708-30a5-4e3f-b95a-11740e604428",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# testing the image in the index 105\n",
        "print('Label: ', X_train[105])\n",
        "plt.imshow(X_train[105].reshape(32,32), cmap=plt.cm.bone);"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label:  [143.1893 141.7164 129.8146 ...  67.7635  68.3613  73.3608]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZIKCXYhMULALkQkKdiEyQcEuRCb8X01s0kMpedZbAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XooLW_JOcnkt",
        "colab_type": "code",
        "outputId": "78960c57-725b-4c8d-d106-068c8a337690",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#printing the value in y_train same index number 105\n",
        "print('Label at 10 : ', y_train[105])"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label at 10 :  8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7Me-h8QuNQI",
        "colab_type": "text"
      },
      "source": [
        "## Step 3: Normalize the inputs from 0 to 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSNYyFnTcnk0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f5c3e016-27f2-4334-dd20-fdd261965fee"
      },
      "source": [
        "#Normalize the inputs for X_train, X_test and X_val\t1\n",
        "X_train[0:2]"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[33.0704, 30.2601, 26.852 , ..., 49.6682, 50.853 , 53.0377],\n",
              "       [86.9591, 87.0685, 88.3735, ..., 75.2206, 76.6396, 79.2865]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gDwQVxtrRuH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "976a15aa-9e17-4e25-f04c-bd298823ee7e"
      },
      "source": [
        "# # normalize inputs from 0-255 to 0-1\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "X_train[0:2]"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.12968785, 0.11866706, 0.10530196, ..., 0.19477727, 0.19942354,\n",
              "        0.20799099],\n",
              "       [0.34101608, 0.3414451 , 0.34656274, ..., 0.29498273, 0.30054745,\n",
              "        0.31092745]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ouVw_zAuche",
        "colab_type": "text"
      },
      "source": [
        "##Step 4: Conert the class matrices / Label into one hot vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Fo5GeMhcnk3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "d063593c-2a8f-4244-ae6d-a8b185586ac4"
      },
      "source": [
        "#Convert the class matrices Y_train, Y_test and Y_val into one hot vectors\t1\n",
        "print('Before one hot conversion :',y_train[0:5])\n",
        "y_train = tf.keras.utils.to_categorical(y_train,num_classes=10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test,num_classes=10)\n",
        "print('After one hot conversion :',y_train[0:5])"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before one hot conversion : [2 6 7 4 4]\n",
            "After one hot conversion : [[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7piwPItaumEV",
        "colab_type": "text"
      },
      "source": [
        "## Step 5: Print train and Test val shapes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8YyZbJ1cnk7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "db3e2fc0-d329-4a9e-f763-17f1b1bebe42"
      },
      "source": [
        "#Print the train, test and val shapes\t2\n",
        "print('Shape of Training set Train:', X_train.shape, 'Test:', X_test.shape )"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of Training set Train: (42000, 1024) Test: (18000, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkCDublEurWJ",
        "colab_type": "text"
      },
      "source": [
        "##Step 6: Visualize the first 10 images in X_train and the corresponding Y_train labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9UQXZwtcnk_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 78
        },
        "outputId": "aa025d2b-ce6d-46ab-8638-adc0a006d214"
      },
      "source": [
        "#Visualize the first 10 images in X_train and the corresponding Y_train labels\t2\n",
        "plt.figure(figsize=(10, 1))\n",
        "for i in range(10):\n",
        "    plt.subplot(1, 10, i+1)\n",
        "    plt.imshow(X_train[i].reshape(32, 32), cmap=\"gray\")\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjwAAAA9CAYAAACpzLMWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhqM4BwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x72 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LapoqwB3tuCm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "89815509-cf5e-4068-d939-60c26b9fbb6a"
      },
      "source": [
        "print(y_train[0:10])"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egr0w6BUuyh8",
        "colab_type": "text"
      },
      "source": [
        "##Step 7: In the train and test loop, define the hyperparameters for the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQG9K5CPcnlC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#In the train and test loop, define the hyperparameters for the model\t4\n",
        "learning_rate = 0.001\n",
        "activation = 'relu'\n",
        "optimizer='sgd'\n",
        "loss='categorical_crossentropy'\n",
        "batch_size = 32\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqYQ2_vZu4xN",
        "colab_type": "text"
      },
      "source": [
        "##Step 8: Create a Sequential model in Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_OmPeLicnlF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create a Sequential model in Keras with input layer with the correct input shape, Hidden Layers, Output Layers and the activation functions\t8\n",
        "#Initialize sequential model\n",
        "model = tf.keras.models.Sequential()\n",
        "#Reshape data from 2D to 1D ->28*28 to 784\n",
        "model.add(tf.keras.layers.Reshape((1024,),input_shape=(1024,)))\n",
        "#Add Dense layer which provides 10 outputs after applying softmax\n",
        "model.add(tf.keras.layers.Dense(100,activation = 'relu'))\n",
        "model.add(tf.keras.layers.Dense(100,activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(100,activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(10,activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(10,activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QL9nMti5u9RO",
        "colab_type": "text"
      },
      "source": [
        "##Step 9: Define the optimizer to be used in this model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9N6rv_kzcnlI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define the optimizer to be used in this model\t2\n",
        "sgd_optimizer = tf.keras.optimizers.SGD(lr=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkF1jsunvCLc",
        "colab_type": "text"
      },
      "source": [
        "##Step 10: Compile the model with the corresponding Loss and metrics to monitor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5nBeS03cnlM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Compile the model with the corresponding Loss and metrics to monitor\t2\n",
        "model.compile(optimizer=sgd_optimizer,loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKU1x9bSvHjY",
        "colab_type": "text"
      },
      "source": [
        "##Step 12: Fit the model and use model.Evaluate to return the score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwsb3BiVcnlT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "ac2f87ca-0016-4aa7-c0ff-0798223ea5fa"
      },
      "source": [
        "#Fit the model and use model.evaluate() to return the score\t1\n",
        "model.fit(X_train,y_train,epochs=10,validation_data=(X_test,y_test),batch_size=32)"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 42000 samples, validate on 18000 samples\n",
            "Epoch 1/10\n",
            "42000/42000 [==============================] - 5s 114us/sample - loss: 2.3038 - acc: 0.1041 - val_loss: 2.3011 - val_acc: 0.1134\n",
            "Epoch 2/10\n",
            "42000/42000 [==============================] - 4s 105us/sample - loss: 2.3002 - acc: 0.1162 - val_loss: 2.2988 - val_acc: 0.1178\n",
            "Epoch 3/10\n",
            "42000/42000 [==============================] - 4s 107us/sample - loss: 2.2981 - acc: 0.1197 - val_loss: 2.2968 - val_acc: 0.1223\n",
            "Epoch 4/10\n",
            "42000/42000 [==============================] - 5s 108us/sample - loss: 2.2961 - acc: 0.1268 - val_loss: 2.2946 - val_acc: 0.1302\n",
            "Epoch 5/10\n",
            "42000/42000 [==============================] - 4s 105us/sample - loss: 2.2937 - acc: 0.1353 - val_loss: 2.2923 - val_acc: 0.1377\n",
            "Epoch 6/10\n",
            "42000/42000 [==============================] - 4s 106us/sample - loss: 2.2914 - acc: 0.1433 - val_loss: 2.2899 - val_acc: 0.1474\n",
            "Epoch 7/10\n",
            "42000/42000 [==============================] - 4s 106us/sample - loss: 2.2888 - acc: 0.1509 - val_loss: 2.2874 - val_acc: 0.1556\n",
            "Epoch 8/10\n",
            "42000/42000 [==============================] - 4s 106us/sample - loss: 2.2861 - acc: 0.1562 - val_loss: 2.2841 - val_acc: 0.1594\n",
            "Epoch 9/10\n",
            "42000/42000 [==============================] - 4s 107us/sample - loss: 2.2830 - acc: 0.1592 - val_loss: 2.2809 - val_acc: 0.1605\n",
            "Epoch 10/10\n",
            "42000/42000 [==============================] - 4s 104us/sample - loss: 2.2795 - acc: 0.1648 - val_loss: 2.2773 - val_acc: 0.1598\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f83851dbef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tX8dfY4kx_ji",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "ef26d80d-c86c-4c67-f6b5-727801ffbbc1"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "reshape_3 (Reshape)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 100)               102500    \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 10)                1010      \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 10)                110       \n",
            "=================================================================\n",
            "Total params: 123,820\n",
            "Trainable params: 123,820\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgZS6aKWvTm7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.evaluate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jhhmdlKvZ9Y",
        "colab_type": "text"
      },
      "source": [
        "#Step 13: Disable Regularization by setting appropriate value for Lambda and check the loss of the NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dl8eLcbFcnlW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "218e8fd7-53b9-4de8-fa81-56a3c94a5f4e"
      },
      "source": [
        "#Disable Regularization by setting appropriate value for Lambda and check the loss of the NN\t2\n",
        "#Normalize the data\n",
        "# example of l2 on a dense layer\n",
        "from keras.layers import Dense\n",
        "from keras.regularizers import l2\n",
        "\n",
        "model2 = tf.keras.models.Sequential()\n",
        "model2.add(tf.keras.layers.Dense(200,activation = 'relu'))\n",
        "model2.add(tf.keras.layers.Dense(200, kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
        "model2.add(tf.keras.layers.Dense(100,activation = 'relu'))\n",
        "model2.add(tf.keras.layers.Dense(10,activation='softmax'))\n",
        "model2.compile(optimizer=sgd_optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "model2.fit(X_train,y_train,epochs=10,validation_data=(X_test,y_test),batch_size=32)"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 42000 samples, validate on 18000 samples\n",
            "Epoch 1/10\n",
            "42000/42000 [==============================] - 7s 166us/sample - loss: 4.2485 - acc: 0.1051 - val_loss: 4.1890 - val_acc: 0.1099\n",
            "Epoch 2/10\n",
            "42000/42000 [==============================] - 6s 151us/sample - loss: 4.1359 - acc: 0.1230 - val_loss: 4.0840 - val_acc: 0.1246\n",
            "Epoch 3/10\n",
            "42000/42000 [==============================] - 6s 153us/sample - loss: 4.0334 - acc: 0.1403 - val_loss: 3.9825 - val_acc: 0.1627\n",
            "Epoch 4/10\n",
            "42000/42000 [==============================] - 7s 155us/sample - loss: 3.9349 - acc: 0.1659 - val_loss: 3.8879 - val_acc: 0.1738\n",
            "Epoch 5/10\n",
            "42000/42000 [==============================] - 6s 154us/sample - loss: 3.8406 - acc: 0.1907 - val_loss: 3.7942 - val_acc: 0.2173\n",
            "Epoch 6/10\n",
            "42000/42000 [==============================] - 7s 156us/sample - loss: 3.7494 - acc: 0.2184 - val_loss: 3.7050 - val_acc: 0.2290\n",
            "Epoch 7/10\n",
            "42000/42000 [==============================] - 6s 154us/sample - loss: 3.6611 - acc: 0.2427 - val_loss: 3.6175 - val_acc: 0.2604\n",
            "Epoch 8/10\n",
            "42000/42000 [==============================] - 6s 155us/sample - loss: 3.5751 - acc: 0.2643 - val_loss: 3.5325 - val_acc: 0.2948\n",
            "Epoch 9/10\n",
            "42000/42000 [==============================] - 6s 153us/sample - loss: 3.4913 - acc: 0.2930 - val_loss: 3.4498 - val_acc: 0.3025\n",
            "Epoch 10/10\n",
            "42000/42000 [==============================] - 6s 152us/sample - loss: 3.4081 - acc: 0.3126 - val_loss: 3.3668 - val_acc: 0.3063\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f837d1ccfd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmOQNkKk72jT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "outputId": "6e604643-6b5f-4cd4-e2c0-20d870939cdf"
      },
      "source": [
        "#Seeing the accuracy increases from 13% to 65% - try increasing the epochs and see it the max accuracy\n",
        "#model2.fit(X_train,y_train,epochs=20,validation_data=(X_test,y_test),batch_size=32)"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 42000 samples, validate on 18000 samples\n",
            "Epoch 1/20\n",
            "42000/42000 [==============================] - 6s 143us/sample - loss: 3.0199 - acc: 0.6862 - val_loss: 2.9467 - val_acc: 0.7079\n",
            "Epoch 2/20\n",
            "42000/42000 [==============================] - 6s 140us/sample - loss: 2.9446 - acc: 0.6952 - val_loss: 2.8756 - val_acc: 0.7148\n",
            "Epoch 3/20\n",
            "42000/42000 [==============================] - 6s 143us/sample - loss: 2.8662 - acc: 0.7047 - val_loss: 2.8063 - val_acc: 0.7212\n",
            "Epoch 4/20\n",
            "42000/42000 [==============================] - 6s 139us/sample - loss: 2.7975 - acc: 0.7082 - val_loss: 2.7416 - val_acc: 0.7263\n",
            "Epoch 5/20\n",
            "42000/42000 [==============================] - 6s 141us/sample - loss: 2.7303 - acc: 0.7148 - val_loss: 2.6770 - val_acc: 0.7313\n",
            "Epoch 6/20\n",
            "42000/42000 [==============================] - 6s 139us/sample - loss: 2.6641 - acc: 0.7229 - val_loss: 2.6150 - val_acc: 0.7383\n",
            "Epoch 7/20\n",
            "42000/42000 [==============================] - 6s 137us/sample - loss: 2.5995 - acc: 0.7279 - val_loss: 2.5559 - val_acc: 0.7408\n",
            "Epoch 8/20\n",
            "42000/42000 [==============================] - 6s 140us/sample - loss: 2.5403 - acc: 0.7340 - val_loss: 2.4982 - val_acc: 0.7486\n",
            "Epoch 9/20\n",
            "42000/42000 [==============================] - 6s 142us/sample - loss: 2.4787 - acc: 0.7386 - val_loss: 2.4422 - val_acc: 0.7506\n",
            "Epoch 10/20\n",
            "42000/42000 [==============================] - 6s 142us/sample - loss: 2.4243 - acc: 0.7426 - val_loss: 2.3903 - val_acc: 0.7546\n",
            "Epoch 11/20\n",
            "42000/42000 [==============================] - 6s 141us/sample - loss: 2.3647 - acc: 0.7494 - val_loss: 2.3349 - val_acc: 0.7597\n",
            "Epoch 12/20\n",
            "42000/42000 [==============================] - 6s 143us/sample - loss: 2.3131 - acc: 0.7530 - val_loss: 2.2866 - val_acc: 0.7628\n",
            "Epoch 13/20\n",
            "42000/42000 [==============================] - 6s 144us/sample - loss: 2.2657 - acc: 0.7549 - val_loss: 2.2450 - val_acc: 0.7648\n",
            "Epoch 14/20\n",
            "42000/42000 [==============================] - 6s 141us/sample - loss: 2.2138 - acc: 0.7617 - val_loss: 2.1956 - val_acc: 0.7691\n",
            "Epoch 15/20\n",
            "42000/42000 [==============================] - 6s 144us/sample - loss: 2.1649 - acc: 0.7639 - val_loss: 2.1530 - val_acc: 0.7726\n",
            "Epoch 16/20\n",
            "42000/42000 [==============================] - 6s 139us/sample - loss: 2.1208 - acc: 0.7675 - val_loss: 2.1058 - val_acc: 0.7754\n",
            "Epoch 17/20\n",
            "42000/42000 [==============================] - 6s 141us/sample - loss: 2.0741 - acc: 0.7702 - val_loss: 2.0649 - val_acc: 0.7778\n",
            "Epoch 18/20\n",
            "42000/42000 [==============================] - 6s 141us/sample - loss: 2.0292 - acc: 0.7742 - val_loss: 2.0233 - val_acc: 0.7803\n",
            "Epoch 19/20\n",
            "42000/42000 [==============================] - 6s 143us/sample - loss: 1.9869 - acc: 0.7772 - val_loss: 1.9833 - val_acc: 0.7824\n",
            "Epoch 20/20\n",
            "42000/42000 [==============================] - 6s 141us/sample - loss: 1.9405 - acc: 0.7821 - val_loss: 1.9502 - val_acc: 0.7822\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f837e208eb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O50yU0xDvj0R",
        "colab_type": "text"
      },
      "source": [
        "##Step 14: Increase the Regularization parameter (Lambda) and check how the loss is for the NN. Record findings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3zB6S9jcnlZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "0abdab36-ffda-4c3b-ae56-b7a01550a433"
      },
      "source": [
        "#Increase the Regularization parameter (Lambda) and check how the loss is for the NN. Record findings\t2\n",
        "model3 = tf.keras.models.Sequential()\n",
        "model3.add(tf.keras.layers.Dense(200,activation = 'relu'))\n",
        "model3.add(tf.keras.layers.Dense(200, kernel_regularizer=l2(0.1), bias_regularizer=l2(0.1)))\n",
        "model3.add(tf.keras.layers.Dense(100,activation = 'relu'))\n",
        "model3.add(tf.keras.layers.Dense(10,activation='softmax'))\n",
        "model3.compile(optimizer=sgd_optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "model3.fit(X_train,y_train,epochs=10,validation_data=(X_test,y_test),batch_size=32)"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 42000 samples, validate on 18000 samples\n",
            "Epoch 1/10\n",
            "42000/42000 [==============================] - 8s 185us/sample - loss: 17.9218 - acc: 0.1084 - val_loss: 14.1681 - val_acc: 0.1216\n",
            "Epoch 2/10\n",
            "42000/42000 [==============================] - 7s 157us/sample - loss: 11.5321 - acc: 0.1277 - val_loss: 9.3148 - val_acc: 0.1367\n",
            "Epoch 3/10\n",
            "42000/42000 [==============================] - 7s 157us/sample - loss: 7.7559 - acc: 0.1470 - val_loss: 6.4459 - val_acc: 0.1487\n",
            "Epoch 4/10\n",
            "42000/42000 [==============================] - 6s 155us/sample - loss: 5.5239 - acc: 0.1624 - val_loss: 4.7489 - val_acc: 0.1754\n",
            "Epoch 5/10\n",
            "42000/42000 [==============================] - 7s 156us/sample - loss: 4.2041 - acc: 0.1802 - val_loss: 3.7458 - val_acc: 0.1889\n",
            "Epoch 6/10\n",
            "42000/42000 [==============================] - 7s 157us/sample - loss: 3.4235 - acc: 0.1921 - val_loss: 3.1527 - val_acc: 0.2091\n",
            "Epoch 7/10\n",
            "42000/42000 [==============================] - 7s 157us/sample - loss: 2.9618 - acc: 0.2163 - val_loss: 2.8017 - val_acc: 0.2416\n",
            "Epoch 8/10\n",
            "42000/42000 [==============================] - 7s 171us/sample - loss: 2.6887 - acc: 0.2249 - val_loss: 2.5939 - val_acc: 0.2524\n",
            "Epoch 9/10\n",
            "42000/42000 [==============================] - 7s 156us/sample - loss: 2.5266 - acc: 0.2505 - val_loss: 2.4708 - val_acc: 0.2321\n",
            "Epoch 10/10\n",
            "42000/42000 [==============================] - 6s 152us/sample - loss: 2.4304 - acc: 0.2626 - val_loss: 2.3970 - val_acc: 0.2308\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f837d31e978>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1RD8kaABmwV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "e6aac6d8-466a-462a-e77d-14c8c5ba9c4f"
      },
      "source": [
        "model3_bn = tf.keras.models.Sequential()\n",
        "model3_bn.add(tf.keras.layers.Dense(200,activation = 'relu'))\n",
        "model3_bn.add(tf.keras.layers.BatchNormalization())\n",
        "model3_bn.add(tf.keras.layers.Dense(100,activation='relu'))\n",
        "model3_bn.add(tf.keras.layers.Dense(10,activation='softmax'))\n",
        "model3_bn.compile(optimizer=sgd_optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "model3_bn.fit(X_train,y_train,epochs=10,validation_data=(X_test,y_test),batch_size=32)"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 42000 samples, validate on 18000 samples\n",
            "Epoch 1/10\n",
            "42000/42000 [==============================] - 7s 162us/sample - loss: 2.2663 - acc: 0.1764 - val_loss: 2.1247 - val_acc: 0.2619\n",
            "Epoch 2/10\n",
            "42000/42000 [==============================] - 6s 147us/sample - loss: 2.0123 - acc: 0.3309 - val_loss: 1.8831 - val_acc: 0.4042\n",
            "Epoch 3/10\n",
            "42000/42000 [==============================] - 6s 149us/sample - loss: 1.7726 - acc: 0.4578 - val_loss: 1.6567 - val_acc: 0.4997\n",
            "Epoch 4/10\n",
            "42000/42000 [==============================] - 6s 150us/sample - loss: 1.5677 - acc: 0.5394 - val_loss: 1.4720 - val_acc: 0.5733\n",
            "Epoch 5/10\n",
            "42000/42000 [==============================] - 6s 145us/sample - loss: 1.4113 - acc: 0.5897 - val_loss: 1.3427 - val_acc: 0.6146\n",
            "Epoch 6/10\n",
            "42000/42000 [==============================] - 6s 149us/sample - loss: 1.2979 - acc: 0.6252 - val_loss: 1.2371 - val_acc: 0.6435\n",
            "Epoch 7/10\n",
            "42000/42000 [==============================] - 6s 145us/sample - loss: 1.2153 - acc: 0.6451 - val_loss: 1.1610 - val_acc: 0.6688\n",
            "Epoch 8/10\n",
            "42000/42000 [==============================] - 6s 143us/sample - loss: 1.1531 - acc: 0.6612 - val_loss: 1.1026 - val_acc: 0.6805\n",
            "Epoch 9/10\n",
            "42000/42000 [==============================] - 6s 143us/sample - loss: 1.1039 - acc: 0.6735 - val_loss: 1.0731 - val_acc: 0.6882\n",
            "Epoch 10/10\n",
            "42000/42000 [==============================] - 6s 148us/sample - loss: 1.0651 - acc: 0.6845 - val_loss: 1.0492 - val_acc: 0.6886\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f837d39eeb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29y0D5h299Qk",
        "colab_type": "text"
      },
      "source": [
        "Increasing the lambda from 0.01 to 0.1 the loss is reducing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0IYRPtCvpSw",
        "colab_type": "text"
      },
      "source": [
        "#Step 15: Network overfit with a small subset of the dataset. Check if the network will overfit when you use no regularization and the loss is very small and accuracy is 100%\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCcONCeacnlc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "3ecff07e-92ad-4f9a-cd51-9aeca8c21900"
      },
      "source": [
        "#Network overfit with a small subset of the dataset. Check if the network will overfit when you use no regularization and the loss is very small and accuracy is 100%.\t2\n",
        "X_train_subset = X_train[0:4200]\n",
        "X_test_subset = X_test[0:4200]\n",
        "y_train_subset = y_train[0:4200]\n",
        "y_test_subset = y_test[0:4200]\n",
        "small_model = tf.keras.Sequential([\n",
        "    # `input_shape` is only required here so that `.summary` works.\n",
        "    tf.keras.layers.Dense(16, activation='elu'),\n",
        "    tf.keras.layers.Dense(16, activation='elu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "small_model.compile(optimizer=sgd_optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "small_model.fit(X_train_subset,y_train_subset,epochs=10,validation_data=(X_test_subset,y_test_subset),batch_size=32)"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 4200 samples, validate on 4200 samples\n",
            "Epoch 1/10\n",
            "4200/4200 [==============================] - 1s 271us/sample - loss: 2.3349 - acc: 0.0848 - val_loss: 2.3209 - val_acc: 0.0783\n",
            "Epoch 2/10\n",
            "4200/4200 [==============================] - 0s 88us/sample - loss: 2.3129 - acc: 0.0886 - val_loss: 2.3142 - val_acc: 0.0786\n",
            "Epoch 3/10\n",
            "4200/4200 [==============================] - 0s 91us/sample - loss: 2.3119 - acc: 0.0819 - val_loss: 2.3165 - val_acc: 0.0833\n",
            "Epoch 4/10\n",
            "4200/4200 [==============================] - 0s 89us/sample - loss: 2.3110 - acc: 0.0895 - val_loss: 2.3145 - val_acc: 0.0783\n",
            "Epoch 5/10\n",
            "4200/4200 [==============================] - 0s 97us/sample - loss: 2.3099 - acc: 0.0888 - val_loss: 2.3127 - val_acc: 0.0812\n",
            "Epoch 6/10\n",
            "4200/4200 [==============================] - 0s 89us/sample - loss: 2.3098 - acc: 0.0900 - val_loss: 2.3127 - val_acc: 0.0829\n",
            "Epoch 7/10\n",
            "4200/4200 [==============================] - 0s 89us/sample - loss: 2.3087 - acc: 0.0921 - val_loss: 2.3123 - val_acc: 0.0824\n",
            "Epoch 8/10\n",
            "4200/4200 [==============================] - 0s 89us/sample - loss: 2.3082 - acc: 0.0902 - val_loss: 2.3127 - val_acc: 0.0814\n",
            "Epoch 9/10\n",
            "4200/4200 [==============================] - 0s 85us/sample - loss: 2.3074 - acc: 0.0924 - val_loss: 2.3113 - val_acc: 0.0824\n",
            "Epoch 10/10\n",
            "4200/4200 [==============================] - 0s 88us/sample - loss: 2.3070 - acc: 0.0926 - val_loss: 2.3109 - val_acc: 0.0829\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f837cba5438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IO_o1fVBJs-O",
        "colab_type": "text"
      },
      "source": [
        "With small model and reduced 10% of the dataset we are able to get 100% accuracy - which is OVERFITTING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXKmKgflvy4y",
        "colab_type": "text"
      },
      "source": [
        "##Step 16: Load the original dataset with all the images and prepare the data for modelling\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuRH5CNjcnlf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "23aae7d2-9cac-4924-8523-3b3ff5517275"
      },
      "source": [
        "#Load the original dataset with all the images and prepare the data for modelling\t4\n",
        "X_test = f['X_test']\n",
        "X_train = f['X_train']\n",
        "X_val = f['X_val']\n",
        "y_test = f['y_test']\n",
        "y_train = f['y_train']\n",
        "y_val = f['y_val']\n",
        "X_test = np.array(X_test)\n",
        "X_test = X_test.reshape(18000,1024)\n",
        "#similarly convert required dataset to numpy array and reshape 32X32 into 1024\n",
        "X_train = np.array(X_train).reshape(42000,1024)\n",
        "#Normalize\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "#one hot encoding labels\n",
        "print('Before one hot conversion :',y_train[0:5])\n",
        "y_train = tf.keras.utils.to_categorical(y_train,num_classes=10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test,num_classes=10)\n",
        "print('After one hot conversion :',y_train[0:5])"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before one hot conversion : [2 6 7 4 4]\n",
            "After one hot conversion : [[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BommiojTv6c-",
        "colab_type": "text"
      },
      "source": [
        "##Step 17: Start with a small Regularization. Keep adjusting the learning rate to check the loss. Record findings\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iL9Ue_Wlcnlh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "f41e4f74-8124-4bdb-e044-720be643e813"
      },
      "source": [
        "#Start with a small Regularization. Keep adjusting the learning rate to check the loss. Record findings\t4\n",
        "model5= tf.keras.models.Sequential()\n",
        "model5.add(tf.keras.layers.Dense(200,activation = 'relu'))\n",
        "model5.add(tf.keras.layers.BatchNormalization())\n",
        "model5.add(tf.keras.layers.Dense(100,activation='relu'))\n",
        "model5.add(tf.keras.layers.Dense(10,activation='softmax'))\n",
        "sgd_optimizer = tf.keras.optimizers.SGD(lr=0.5)\n",
        "model5.compile(optimizer=sgd_optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "model5.fit(X_train,y_train,epochs=10,validation_data=(X_test,y_test),batch_size=32)"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 42000 samples, validate on 18000 samples\n",
            "Epoch 1/10\n",
            "42000/42000 [==============================] - 8s 184us/sample - loss: 1.7165 - acc: 0.4050 - val_loss: 1.9906 - val_acc: 0.4037\n",
            "Epoch 2/10\n",
            "42000/42000 [==============================] - 7s 161us/sample - loss: 1.3903 - acc: 0.5483 - val_loss: 2.3490 - val_acc: 0.3471\n",
            "Epoch 3/10\n",
            "42000/42000 [==============================] - 7s 157us/sample - loss: 1.2811 - acc: 0.5901 - val_loss: 1.4437 - val_acc: 0.5204\n",
            "Epoch 4/10\n",
            "42000/42000 [==============================] - 7s 158us/sample - loss: 1.2357 - acc: 0.6097 - val_loss: 3.2726 - val_acc: 0.2388\n",
            "Epoch 5/10\n",
            "42000/42000 [==============================] - 7s 160us/sample - loss: 1.1813 - acc: 0.6293 - val_loss: 1.6166 - val_acc: 0.5287\n",
            "Epoch 6/10\n",
            "42000/42000 [==============================] - 7s 160us/sample - loss: 1.1494 - acc: 0.6407 - val_loss: 1.0619 - val_acc: 0.6658\n",
            "Epoch 7/10\n",
            "42000/42000 [==============================] - 7s 156us/sample - loss: 1.1319 - acc: 0.6500 - val_loss: 1.1522 - val_acc: 0.6382\n",
            "Epoch 8/10\n",
            "42000/42000 [==============================] - 7s 163us/sample - loss: 1.1225 - acc: 0.6520 - val_loss: 1.3836 - val_acc: 0.5747\n",
            "Epoch 9/10\n",
            "42000/42000 [==============================] - 7s 156us/sample - loss: 1.1095 - acc: 0.6569 - val_loss: 1.2890 - val_acc: 0.5807\n",
            "Epoch 10/10\n",
            "42000/42000 [==============================] - 7s 160us/sample - loss: 1.0992 - acc: 0.6591 - val_loss: 1.3076 - val_acc: 0.5823\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f837c1e4278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwTIhvP2MmS9",
        "colab_type": "text"
      },
      "source": [
        "<font color=\"red\">Learning Rate 0.001</font>\n",
        "<br>Epoch 1/10\n",
        "42000/42000 [=] - 8s 184us/sample - loss: 2.2717 - acc: 0.1758 - val_loss: 2.1247 - val_acc: 0.2543\n",
        "<br>Epoch 10/10\n",
        "42000/42000 [=] - 7s 158us/sample - loss: 1.0986 - acc: 0.6772 - val_loss: 1.0553 - val_acc: 0.6950\n",
        "<br><br><font color=\"red\">Learning Rate 0.01</font>\n",
        "<br>Epoch 1/10\n",
        "42000/42000 [=] - 8s 180us/sample - loss: 1.6713 - acc: 0.4598 - val_loss: 1.4193 - val_acc: 0.5287\n",
        "<br>Epoch 10/10\n",
        "42000/42000 [=] - 6s 152us/sample - loss: 0.9359 - acc: 0.7125 - val_loss: 1.2810 - val_acc: 0.5940\n",
        "<br><br><font color=\"red\">Learning Rate 0.05</font>\n",
        "<br>Epoch 1/10\n",
        "42000/42000 [=] - 8s 190us/sample - loss: 1.6779 - acc: 0.4472 - val_loss: 2.5653 - val_acc: 0.2830\n",
        "<br>Epoch 10/10\n",
        "42000/42000 [=] - 7s 159us/sample - loss: 1.2071 - acc: 0.6093 - val_loss: 1.1955 - val_acc: 0.6128\n",
        "<br><br><font color=\"red\">Learning Rate 0.1</font>\n",
        "<br>Epoch 1/10\n",
        "42000/42000 [=] - 8s 186us/sample - loss: 1.6702 - acc: 0.4298 - val_loss: 3.2386 - val_acc: 0.2166\n",
        "<br>Epoch 10/10\n",
        "42000/42000 [=] - 7s 162us/sample - loss: 1.2186 - acc: 0.6075 - val_loss: 1.4296 - val_acc: 0.5257\n",
        "<br><br><font color=\"red\">Learning Rate 0.3</font>\n",
        "<br>Epoch 1/10\n",
        "42000/42000 [=] - 8s 187us/sample - loss: 1.6386 - acc: 0.4402 - val_loss: 1.5808 - val_acc: 0.4878\n",
        "<br>Epoch 10/10\n",
        "42000/42000 [=] - 8s 200us/sample - loss: 0.9615 - acc: 0.7027 - val_loss: 1.2401 - val_acc: 0.6176\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaejhOkjMRC5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OqLCHh8wcPL",
        "colab_type": "text"
      },
      "source": [
        "##Step 18: Perform Hyperparameter Optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2Qc1pCYcnll",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "cbec9b0f-9d33-4cb7-99d5-96ac2bc14a06"
      },
      "source": [
        "#Perform Hyperparameter Optimization . Record findings\t4\n",
        "#changing optimizer to Adam\n",
        "model5= tf.keras.models.Sequential()\n",
        "model5.add(tf.keras.layers.Dense(1024,activation = 'relu'))\n",
        "model5.add(tf.keras.layers.BatchNormalization())\n",
        "model5.add(tf.keras.layers.Dense(512,activation='relu'))\n",
        "model5.add(tf.keras.layers.Dense(256,activation='relu'))\n",
        "model5.add(tf.keras.layers.Dense(128,activation='relu'))\n",
        "model5.add(tf.keras.layers.Dense(10,activation='softmax'))\n",
        "adam_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
        "model5.compile(optimizer=adam_optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "model5.fit(X_train,y_train,epochs=10,validation_data=(X_test,y_test),batch_size=64)"
      ],
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 42000 samples, validate on 18000 samples\n",
            "Epoch 1/10\n",
            "42000/42000 [==============================] - 23s 558us/sample - loss: 1.3400 - acc: 0.5550 - val_loss: 2.4633 - val_acc: 0.2915\n",
            "Epoch 2/10\n",
            "42000/42000 [==============================] - 21s 512us/sample - loss: 0.9914 - acc: 0.6861 - val_loss: 1.2912 - val_acc: 0.6069\n",
            "Epoch 3/10\n",
            "42000/42000 [==============================] - 21s 497us/sample - loss: 0.8684 - acc: 0.7258 - val_loss: 0.9554 - val_acc: 0.6959\n",
            "Epoch 4/10\n",
            "42000/42000 [==============================] - 21s 497us/sample - loss: 0.7765 - acc: 0.7547 - val_loss: 1.1173 - val_acc: 0.6419\n",
            "Epoch 5/10\n",
            "42000/42000 [==============================] - 21s 495us/sample - loss: 0.7040 - acc: 0.7793 - val_loss: 0.9174 - val_acc: 0.7161\n",
            "Epoch 6/10\n",
            "42000/42000 [==============================] - 21s 503us/sample - loss: 0.6617 - acc: 0.7902 - val_loss: 1.3836 - val_acc: 0.5947\n",
            "Epoch 7/10\n",
            "42000/42000 [==============================] - 21s 499us/sample - loss: 0.6175 - acc: 0.8062 - val_loss: 0.8851 - val_acc: 0.7204\n",
            "Epoch 8/10\n",
            "42000/42000 [==============================] - 21s 495us/sample - loss: 0.5859 - acc: 0.8129 - val_loss: 1.1193 - val_acc: 0.6583\n",
            "Epoch 9/10\n",
            "42000/42000 [==============================] - 21s 495us/sample - loss: 0.5641 - acc: 0.8182 - val_loss: 0.7018 - val_acc: 0.7799\n",
            "Epoch 10/10\n",
            "42000/42000 [==============================] - 21s 497us/sample - loss: 0.5378 - acc: 0.8287 - val_loss: 0.8199 - val_acc: 0.7449\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f837a779400>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 195
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVQ5eyJzRChU",
        "colab_type": "text"
      },
      "source": [
        "Model Config:<font color=\"red\">\n",
        "BatchNormalization, Adam Optimizer with learning rate 0.001</font>\n",
        "<br>Epoch 1/10\n",
        "42000/42000 - 9s 209us/sample - loss: 1.4179 - acc: 0.5520 - val_loss: 1.5119 - val_acc: 0.5004\n",
        "<br>Epoch 10/10\n",
        "42000/42000  - 7s 178us/sample - loss: 0.7657 - acc: 0.7663 - val_loss: 1.0693 - val_acc: 0.6824\n",
        "<br>\n",
        "Model Config:\n",
        "BatchNormalization, Adam Optimizer with <font color=\"red\">learning rate 0.01</font>\n",
        "<br>\n",
        "Epoch 1/10\n",
        "42000/42000  - 10s 240us/sample - loss: 1.6192 - acc: 0.4372 - val_loss: 2.7127 - val_acc: 0.3062\n",
        "<br>Epoch 10/10\n",
        "42000/42000  - 8s 202us/sample - loss: 1.0224 - acc: 0.6829 - val_loss: 1.0512 - val_acc: 0.6731\n",
        "Model Config:\n",
        "BatchNormalization, Adam Optimizer with learning rate 0.001\n",
        "changing <font color=\"red\">batch_size from 32 to 64 </font>\n",
        "<br>Epoch 1/10\n",
        "42000/42000  - 7s 163us/sample - loss: 1.4260 - acc: 0.5518 - val_loss: 1.5168 - val_acc: 0.4904\n",
        "<br>Epoch 10/10\n",
        "42000/42000  - 5s 121us/sample - loss: 0.6674 - acc: 0.8002 - val_loss: 1.0364 - val_acc: 0.6982\n",
        "<br><br>\n",
        "Epoch 1/10\n",
        "42000/42000  - 23s 558us/sample - loss: 1.3400 - acc: 0.5550 - val_loss: 2.4633 - val_acc: 0.2915\n",
        "<br>Epoch 10/10\n",
        "42000/42000  - 21s 497us/sample - loss: 0.5378 - acc: 0.8287 - val_loss: 0.8199 - val_acc: 0.7449\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kMSyX9hwgyf",
        "colab_type": "text"
      },
      "source": [
        "### Hyperparameter Optimization using RandomSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhMVm0jtj7qu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "7218e74d-086a-419a-ac49-03e879d37974"
      },
      "source": [
        "\n",
        "def create_model(optimizer='rmsprop', init='glorot_uniform'):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(512, input_shape=(1024,)))\n",
        "    model.add(Activation('relu')) \n",
        "    model.add(Dropout(0.2))  \n",
        "    model.add(Dense(512,init=init))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(10,init=init))\n",
        "    model.add(Activation('softmax')) \n",
        "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy']) \n",
        "    return model\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
        "from time import time\n",
        "start= time()\n",
        "model = KerasClassifier(build_fn=create_model,verbose=1)\n",
        "n_iter_search = 16 # Number of parameter settings that are sampled.\n",
        "optimizers = ['rmsprop','sgd', 'adam']\n",
        "init = ['glorot_uniform', 'normal', 'uniform']\n",
        "epochs = np.array([10, 15])\n",
        "batches = np.array([32,64])\n",
        "param_grid = dict(optimizer=optimizers, nb_epoch=epochs, batch_size=batches, init=init)\n",
        "\n",
        "random_search = RandomizedSearchCV(estimator=model, \n",
        "                                   param_distributions=param_grid,\n",
        "                                   n_iter=n_iter_search)\n",
        "random_search.fit(X_train, y_train)\n",
        "print(\"Best: %f using %s\" % (random_search.best_score_, random_search.best_params_))\n",
        "means = random_search.cv_results_['mean_test_score']\n",
        "stds = random_search.cv_results_['std_test_score']\n",
        "params = random_search.cv_results_['params']\n",
        "print(\"total time:\",time()-start)\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-a5f0062566a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0moptimizers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'rmsprop'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'sgd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'adam'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0minit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'glorot_uniform'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'normal'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'uniform'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mbatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbG61Canw-Ml",
        "colab_type": "text"
      },
      "source": [
        "##Step 19: Best hyperparameters found in the previous step (Step 18)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neRMHs2_cnls",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Set the best hyperparameters found in the previous step. Check the Network’s accuracy.\t7"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}