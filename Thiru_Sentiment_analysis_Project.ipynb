{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Thiru-Sentiment-analysis-Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jpthirumalai/aiml/blob/master/Thiru_Sentiment_analysis_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xT7MKZuMRaCg"
      },
      "source": [
        "# Sentiment Classification\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Wq4RCyyPSYRp"
      },
      "source": [
        "## Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NGCtiXUhSWss",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "01605210-c5d8-4fcc-88b4-59765367edc6"
      },
      "source": [
        "from keras.datasets import imdb\n",
        "\n",
        "vocab_size = 10000 #vocab size\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocab_size) # vocab_size is no.of words to consider from the dataset, ordering based on frequency."
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fCPC_WN-eCyw",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "vocab_size = 10000 #vocab size\n",
        "maxlen = 300  #number of word used from each review"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qMEsHYrWxdtk"
      },
      "source": [
        "## Train test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "h0g381XzeCyz",
        "colab": {}
      },
      "source": [
        "#load dataset as a list of ints\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocab_size)\n",
        "#make all sequences of the same length\n",
        "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test =  pad_sequences(x_test, maxlen=maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Jy6n-uM2eCy2",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "# X = np.concatenate((x_train, x_test), axis=0)\n",
        "# Y = np.concatenate((y_train, y_test), axis=0)\n",
        "X = np.concatenate((x_train, x_test), axis=0)\n",
        "Y = np.concatenate((y_train, y_test), axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FreHfojSUyT0",
        "colab_type": "text"
      },
      "source": [
        "## Exploring Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tZhMAgaNeCy5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "1d3fd466-47ab-49b4-fd20-e6c1c2a14c11"
      },
      "source": [
        "print(\"Categories:\", np.unique(Y))\n",
        "print(\"Number of unique words:\", len(np.unique(np.hstack(X))))\n",
        "\n",
        "length = [len(i) for i in X]\n",
        "print(\"Average Review length:\", np.mean(length))\n",
        "print(\"Standard Deviation:\", round(np.std(length)))\n",
        "\n",
        "print(\"Number of Negative reviews \",Y[Y==0].size)\n",
        "print(\"Number of Positive reviews \",Y[Y==1].size)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Categories: [0 1]\n",
            "Number of unique words: 9999\n",
            "Average Review length: 300.0\n",
            "Standard Deviation: 0.0\n",
            "Number of Negative reviews  25000\n",
            "Number of Positive reviews  25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNMAaMVUUyT4",
        "colab_type": "text"
      },
      "source": [
        "### Dataset is Eauivally distributed labels - Number of positeve reviews 25000 & negative reviews 25000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpiFees6UyT5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "d21b3a79-ac17-414f-f46d-800fc5d76562"
      },
      "source": [
        "print(\"Label:\", Y[10])\n",
        "print(\"Data:\", X[10])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label: 1\n",
            "Data: [   6  346  137   11    4 2768  295   36 7740  725    6 3208  273   11\n",
            "    4 1513   15 1367   35  154    2  103    2  173    7   12   36  515\n",
            " 3547   94 2547 1722    5 3547   36  203   30  502    8  361   12    8\n",
            "  989  143    4 1172 3404   10   10  328 1236    9    6   55  221 2989\n",
            "    5  146  165  179  770   15   50  713   53  108  448   23   12   17\n",
            "  225   38   76 4397   18  183    8   81   19   12   45 1257    8  135\n",
            "   15    2  166    4  118    7   45    2   17  466   45    2    4   22\n",
            "  115  165  764 6075    5 1030    8 2973   73  469  167 2127    2 1568\n",
            "    6   87  841   18    4   22    4  192   15   91    7   12  304  273\n",
            " 1004    4 1375 1172 2768    2   15    4   22  764   55 5773    5   14\n",
            " 4233 7444    4 1375  326    7    4 4760 1786    8  361 1236    8  989\n",
            "   46    7    4 2768   45   55  776    8   79  496   98   45  400  301\n",
            "   15    4 1859    9    4  155   15   66    2   84    5   14   22 1534\n",
            "   15   17    4  167    2   15   75   70  115   66   30  252    7  618\n",
            "   51    9 2161    4 3130    5   14 1525    8 6584   15    2  165  127\n",
            " 1921    8   30  179 2532    4   22    9  906   18    6  176    7 1007\n",
            " 1005    4 1375  114    4  105   26   32   55  221   11   68  205   96\n",
            "    5    4  192   15    4  274  410  220  304   23   94  205  109    9\n",
            "   55   73  224  259 3786   15    4   22  528 1645   34    4  130  528\n",
            "   30  685  345   17    4  277  199  166  281    5 1030    8   30  179\n",
            " 4442  444    2    9    6  371   87  189   22    5   31    7    4  118\n",
            "    7    4 2068  545 1178  829]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zN0sX0niUyT8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "2dadf505-4345-4331-cefa-73aa6806a3b2"
      },
      "source": [
        "def decode_review(n):\n",
        "    index = imdb.get_word_index()\n",
        "    reverse_index = dict([(value, key) for (key, value) in index.items()]) \n",
        "    decoded = \" \".join( [reverse_index.get(i - 3, \"#\") for i in X[n]] )\n",
        "    return decoded\n",
        "print(decode_review(10)) "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 1s 0us/step\n",
            "a short while in the cell together they stumble upon a hiding place in the wall that contains an old # after # part of it they soon realise its magical powers and realise they may be able to use it to break through the prison walls br br black magic is a very interesting topic and i'm actually quite surprised that there aren't more films based on it as there's so much scope for things to do with it it's fair to say that # makes the best of it's # as despite it's # the film never actually feels restrained and manages to flow well throughout director eric # provides a great atmosphere for the film the fact that most of it takes place inside the central prison cell # that the film feels very claustrophobic and this immensely benefits the central idea of the prisoners wanting to use magic to break out of the cell it's very easy to get behind them it's often said that the unknown is the thing that really # people and this film proves that as the director # that we can never really be sure of exactly what is round the corner and this helps to ensure that # actually does manage to be quite frightening the film is memorable for a lot of reasons outside the central plot the characters are all very interesting in their own way and the fact that the book itself almost takes on its own character is very well done anyone worried that the film won't deliver by the end won't be disappointed either as the ending both makes sense and manages to be quite horrifying overall # is a truly great horror film and one of the best of the decade highly recommended viewing\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYFjIQjnUyT_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d099137b-70a4-4c2e-9d6d-530ecafb3e42"
      },
      "source": [
        "print(\"Data size\",X.shape)\n",
        "print(\"Label size\",Y.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data size (50000, 300)\n",
            "Label size (50000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzmwFc1lUyUC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Train Test Split 80:20 ratio that is 40K:10K\n",
        "x_test = X[:10000] #get first 10000 as test\n",
        "y_test = Y[:10000]\n",
        "\n",
        "x_train = X[10000:] #from 10000 till 50k total 40000 as train data\n",
        "y_train = Y[10000:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIVSTwEKUyUE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "f3a615ad-404b-4715-ceef-87f45c48247b"
      },
      "source": [
        "print(\"Train data size\",x_train.shape)\n",
        "print(\"Test data size\",x_test.shape)\n",
        "\n",
        "print(\"Train Label size\",y_train.shape)\n",
        "print(\"Test Label size\",y_train.shape)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train data size (40000, 300)\n",
            "Test data size (10000, 300)\n",
            "Train Label size (40000,)\n",
            "Test Label size (40000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dybtUgUReCy8"
      },
      "source": [
        "## Build Keras Embedding Layer Model\n",
        "We can think of the Embedding layer as a dicionary that maps a index assigned to a word to a word vector. This layer is very flexible and can be used in a few ways:\n",
        "\n",
        "* The embedding layer can be used at the start of a larger deep learning model. \n",
        "* Also we could load pre-train word embeddings into the embedding layer when we create our model.\n",
        "* Use the embedding layer to train our own word2vec models.\n",
        "\n",
        "The keras embedding layer doesn't require us to onehot encode our words, instead we have to give each word a unqiue intger number as an id. For the imdb dataset we've loaded this has already been done, but if this wasn't the case we could use sklearn [LabelEncoder](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-OSrpRxUyUK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "78661c5f-6f24-4ec6-a654-2248b699cda2"
      },
      "source": [
        "embed_dim = 2\n",
        "lstm_out = 196\n",
        "vocabulary = imdb.get_word_index()\n",
        "vocabSize = len(vocabulary)\n",
        "print(\"Embedding Dimension\",embed_dim)\n",
        "print(\"Vocabulary size\",vocabSize)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Embedding Dimension 2\n",
            "Vocabulary size 88584\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "A5OLM4eBeCy9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "061b2792-98ec-4477-f585-aaa58f549415"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, Dropout, LSTM, SpatialDropout1D, Flatten\n",
        "\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocabSize, embed_dim,input_length = 300))\n",
        "model.add(Flatten())\n",
        "# dropout regularization\n",
        "model.add(Dropout(rate=0.5))\n",
        "\n",
        "# small dense layer. It's role is to analyze the distribution of points from embedding\n",
        "model.add(Dense(5))\n",
        "\n",
        "# final neuron, with sigmoid activation for binary classification\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# model.add(LSTM(32, dropout=0.2, recurrent_dropout=0.2))\n",
        "# model.add(Dense(1, activation='sigmoid'))\n",
        "# compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "# summarize the model\n",
        "print(model.summary())\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 300, 2)            177168    \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 600)               0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 600)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 5)                 3005      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 6         \n",
            "=================================================================\n",
            "Total params: 180,179\n",
            "Trainable params: 180,179\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqYizqKpUyUP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "7b9daecc-9649-4af0-89b6-ce3c8699f6e7"
      },
      "source": [
        "batch_size = 100\n",
        "# fit the model\n",
        "history = model.fit(x_train, y_train, validation_split=0.3, epochs=20, batch_size=batch_size, verbose = 2)\n",
        "# evaluate the model\n",
        "# loss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\n",
        "# print('Accuracy: %f' % (accuracy*100))\n",
        "# print(model.summary())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "280/280 - 2s - loss: 0.6590 - accuracy: 0.5962 - val_loss: 0.4959 - val_accuracy: 0.8101\n",
            "Epoch 2/20\n",
            "280/280 - 2s - loss: 0.3854 - accuracy: 0.8344 - val_loss: 0.2905 - val_accuracy: 0.8852\n",
            "Epoch 3/20\n",
            "280/280 - 2s - loss: 0.2917 - accuracy: 0.8792 - val_loss: 0.2632 - val_accuracy: 0.8900\n",
            "Epoch 4/20\n",
            "280/280 - 2s - loss: 0.2599 - accuracy: 0.8928 - val_loss: 0.2559 - val_accuracy: 0.8966\n",
            "Epoch 5/20\n",
            "280/280 - 2s - loss: 0.2415 - accuracy: 0.9028 - val_loss: 0.2511 - val_accuracy: 0.8971\n",
            "Epoch 6/20\n",
            "280/280 - 2s - loss: 0.2292 - accuracy: 0.9075 - val_loss: 0.2578 - val_accuracy: 0.8937\n",
            "Epoch 7/20\n",
            "280/280 - 2s - loss: 0.2222 - accuracy: 0.9095 - val_loss: 0.2536 - val_accuracy: 0.8963\n",
            "Epoch 8/20\n",
            "280/280 - 1s - loss: 0.2181 - accuracy: 0.9120 - val_loss: 0.2546 - val_accuracy: 0.8940\n",
            "Epoch 9/20\n",
            "280/280 - 2s - loss: 0.2082 - accuracy: 0.9149 - val_loss: 0.2570 - val_accuracy: 0.8946\n",
            "Epoch 10/20\n",
            "280/280 - 1s - loss: 0.2043 - accuracy: 0.9173 - val_loss: 0.2614 - val_accuracy: 0.8942\n",
            "Epoch 11/20\n",
            "280/280 - 1s - loss: 0.2008 - accuracy: 0.9193 - val_loss: 0.2699 - val_accuracy: 0.8912\n",
            "Epoch 12/20\n",
            "280/280 - 1s - loss: 0.1994 - accuracy: 0.9172 - val_loss: 0.2664 - val_accuracy: 0.8926\n",
            "Epoch 13/20\n",
            "280/280 - 1s - loss: 0.1957 - accuracy: 0.9205 - val_loss: 0.2710 - val_accuracy: 0.8903\n",
            "Epoch 14/20\n",
            "280/280 - 2s - loss: 0.1914 - accuracy: 0.9221 - val_loss: 0.2723 - val_accuracy: 0.8913\n",
            "Epoch 15/20\n",
            "280/280 - 1s - loss: 0.1905 - accuracy: 0.9231 - val_loss: 0.2744 - val_accuracy: 0.8900\n",
            "Epoch 16/20\n",
            "280/280 - 1s - loss: 0.1898 - accuracy: 0.9228 - val_loss: 0.2792 - val_accuracy: 0.8874\n",
            "Epoch 17/20\n",
            "280/280 - 1s - loss: 0.1903 - accuracy: 0.9218 - val_loss: 0.2769 - val_accuracy: 0.8908\n",
            "Epoch 18/20\n",
            "280/280 - 2s - loss: 0.1882 - accuracy: 0.9221 - val_loss: 0.2803 - val_accuracy: 0.8907\n",
            "Epoch 19/20\n",
            "280/280 - 1s - loss: 0.1864 - accuracy: 0.9253 - val_loss: 0.2816 - val_accuracy: 0.8879\n",
            "Epoch 20/20\n",
            "280/280 - 1s - loss: 0.1857 - accuracy: 0.9227 - val_loss: 0.2812 - val_accuracy: 0.8903\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRB-xMW5UyUR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3c539481-0748-4e69-c35b-d0ad815aada2"
      },
      "source": [
        "# evaluate the model\n",
        "loss, accuracy = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Accuracy: %f{0}'.format(accuracy*100))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.2967 - accuracy: 0.8815\n",
            "Accuracy: %f88.15000057220459\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMIO3hFOUyUU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "24f509f2-d29a-419b-e078-1a93cb528d23"
      },
      "source": [
        "history.history.keys()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAjMQYuqUyUX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot_accuracy(history, miny=None):\n",
        "    acc = history.history['accuracy']\n",
        "    test_acc = history.history['val_accuracy']\n",
        "    epochs = range(len(acc))\n",
        "    plt.plot(epochs, acc)\n",
        "    plt.plot(epochs, test_acc)\n",
        "    if miny:\n",
        "        plt.ylim(miny, 1.0)\n",
        "        plt.title('accuracy') \n",
        "        plt.xlabel('epoch')\n",
        "        plt.figure()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2ygChL6UyUZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "b1aeb152-8090-4925-f392-d6fe095dcd4c"
      },
      "source": [
        "plot_accuracy(history)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hNAiI2hUyUd",
        "colab_type": "text"
      },
      "source": [
        "## From the above graph it is ensured the model is not overfitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3rYHpluUyUd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "cc3e4ae4-d7b5-488b-b6cd-6bd1389952b5"
      },
      "source": [
        "print(X[34])\n",
        "print(decode_review(34))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[   9  918    8 6651    4  455    2    4 2335  832   32    4   96    8\n",
            "    4 9877 1903    2    7    4    2 4681  121  132    5 2773  297   46\n",
            "   68  477 3610  985  429  257   85   10   10  107  183  759   46   11\n",
            "   14   22   31    9    4 2299  603   34    2    2  382    4  833 5102\n",
            "    7   22  228    7   32   58   27 1956 1053   23  998    2  967    2\n",
            "  315    4 2226    5 2084    4   85    9    4  480 5633 1381    7 2901\n",
            " 2567   63  166    4   22 4152 5754    8    4  744   11  175   85 2550\n",
            "    2  475  455 4127    9    6 5360   22   15  127  164    8 6802    4\n",
            " 2577    7   94 1020  177    5 1051 2173  739  576 1815  469    4   22\n",
            "   27 1153    2  328 2666  187   27  523    5 2391    2 6521   27  239\n",
            " 1503    4  644    2    2 3372    6  176    7 1279 6840   21  996    8\n",
            " 2522   19   41  196    2    5 1815 6524 8920   44    4  771    7    2\n",
            "    4  360    7    4  156   26 1053   11 1420    5 9364  555    4   91\n",
            "  906    7   63 1085 3281 3544  397   41 3967 5706  125   34    4 9539\n",
            " 4127    4  114    9  964 1835   39  380    8 1363   19  141 5400  844\n",
            "   17    4 4127 4042 1861    6  968   11    4 5244 2059   15    2    5\n",
            " 6082    4  719    2  261   45 3084    8 1408   15    2   26 1089 2373\n",
            "   19 2038 1438    4  326   15    6 4127  100  114 1060  429    6  686\n",
            "  406    2    5 1671   12   46   38    2    9 1254 1755    2  475  455\n",
            " 4127    9   66   31   18    2    7    4  132 1918 2773 7179   39    4\n",
            "  522 2226   91   80  216  245   39    4   22 5870   68 1828   11 2793\n",
            "    5    2   68 2698   19 4853]\n",
            "is forced to pursue the killer # the hunt leads all the way to the desolate ice # of the # ocean where man and beast play out their final fatal battle against each other br br two things stand out in this film one is the haunting score by # # perhaps the greatest composer of film music of all time his talents wasted on various # rate # during the 70s and 80s the other is the amazing widescreen photography of ted moore which makes the film consistently pleasing to the eye in every other department #  killer whale is a shoddy film that does nothing to enhance the reputation of its talented cast and crew harris appears extremely ill throughout the film his hair # black rings around his eyes and skin # pale his performance lacks the usual # # strikes a lot of sexy poses but fails to convince with her long # and ill informed explanations about the ways of # the rest of the actors are wasted in brief and undeveloped roles the most memorable of which sees bo derek getting her leg bitten off by the vengeful whale the plot is total nonsense from start to finish with such preposterous sequences as the whale deliberately starting a fire in the fishing village that # and destroys the local # although it's credible to suppose that # are intelligent creatures with genuine emotions the idea that a whale could plot revenge against a single human # and carry it out so # is utterly absurd #  killer whale is really one for # of the man vs beast cycle from the late 70s most will come away from the film shaking their heads in disbelief and # their teeth with despair\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vc58UPZQUyUf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk import word_tokenize\n",
        "\n",
        "def vectorize(reviewsequence,max_review_length=300):\n",
        "    words = word_tokenize( reviewsequence)\n",
        "#     print(len(words))\n",
        "    word2index = imdb.get_word_index()\n",
        "    result=[]\n",
        "    for word in words:\n",
        "        try:\n",
        "            word_index = word2index[word]+3\n",
        "            if word=='#':\n",
        "                continue\n",
        "            else:\n",
        "                if word_index>=10000:\n",
        "                    continue\n",
        "                else:\n",
        "                    result.append(word_index)\n",
        "        except KeyError:\n",
        "            continue\n",
        "#     print(\"Length of given review: {0}\".format(len(result)))\n",
        "#    result=pad_sequences([result],maxlen=max_review_length)\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wl3k8TFzWxe9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "cf6ce5b5-0321-4ff0-e0a7-c7284d85716d"
      },
      "source": [
        " import nltk\n",
        " nltk.download('punkt')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XW5FgDlwUyUi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "b4204fa8-5dea-467a-8271-36c6bd74e1d9"
      },
      "source": [
        "a = vectorize(decode_review(34),300)\n",
        "print(a)\n",
        "Y[34]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[9, 918, 8, 6651, 4, 455, 4, 2335, 832, 32, 4, 96, 8, 4, 9877, 1903, 7, 4, 4681, 121, 132, 5, 2773, 297, 46, 68, 477, 3610, 985, 429, 257, 85, 10, 10, 107, 183, 759, 46, 11, 14, 22, 31, 9, 4, 2299, 603, 34, 382, 4, 833, 5102, 7, 22, 228, 7, 32, 58, 27, 1956, 1053, 23, 998, 967, 315, 4, 2226, 5, 2084, 4, 85, 9, 4, 480, 5633, 1381, 7, 2901, 2567, 63, 166, 4, 22, 4152, 5754, 8, 4, 744, 11, 175, 85, 2550, 475, 455, 4127, 9, 6, 5360, 22, 15, 127, 164, 8, 6802, 4, 2577, 7, 94, 1020, 177, 5, 1051, 2173, 739, 576, 1815, 469, 4, 22, 27, 1153, 328, 2666, 187, 27, 523, 5, 2391, 6521, 27, 239, 1503, 4, 644, 3372, 6, 176, 7, 1279, 6840, 21, 996, 8, 2522, 19, 41, 196, 5, 1815, 6524, 8920, 44, 4, 771, 7, 4, 360, 7, 4, 156, 26, 1053, 11, 1420, 5, 9364, 555, 4, 91, 906, 7, 63, 1085, 3281, 3544, 397, 41, 3967, 5706, 125, 34, 4, 9539, 4127, 4, 114, 9, 964, 1835, 39, 380, 8, 1363, 19, 141, 5400, 844, 17, 4, 4127, 4042, 1861, 6, 968, 11, 4, 5244, 2059, 15, 5, 6082, 4, 719, 261, 12, 3579, 3084, 8, 1408, 15, 26, 1089, 2373, 19, 2038, 1438, 4, 326, 15, 6, 4127, 100, 114, 1060, 429, 6, 686, 406, 5, 1671, 12, 46, 38, 9, 1254, 1755, 475, 455, 4127, 9, 66, 31, 18, 7, 4, 132, 1918, 2773, 7179, 39, 4, 522, 2226, 91, 80, 216, 245, 39, 4, 22, 5870, 68, 1828, 11, 2793, 5, 68, 2698, 19, 4853]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqoCV3QRUyUk",
        "colab_type": "text"
      },
      "source": [
        "#### Above print of elements of 34th review -  Verified getting the same list again - Verified and Decode and Vetorize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EY_ig4RUyUk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "814da739-2321-48d2-a6b6-6cd9f53ec230"
      },
      "source": [
        "print(decode_review(0))\n",
        "Y[0]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert # is an amazing actor and now the same being director # father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for # and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also # to the two little boy's that played the # of norman and paul they were just brilliant children are often left out of the # list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Igq8Qm8GeCzG"
      },
      "source": [
        "## Retrive the output of each layer in keras for a given single test sample from the trained model you built"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQByROC2UyUn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "word2index = imdb.get_word_index()\n",
        "\n",
        "# embedding_5 (Embedding)      (None, 300, 128)          1280000   \n",
        "# _________________________________________________________________\n",
        "# flatten_4 (Flatten)          (None, 38400)             0         \n",
        "# _________________________________________________________________\n",
        "# dropout (Dropout)            (None, 38400)             0         \n",
        "# _________________________________________________________________\n",
        "# dense_5 (Dense)              (None, 5)                 192005    \n",
        "# _________________________________________________________________\n",
        "# dense_6 (Dense)              (None, 1)                 6         \n",
        "# =================================================================\n",
        "\n",
        "get_embed_out = keras.backend.function(\n",
        "    [model.layers[0].input],\n",
        "    [model.layers[1].output])\n",
        "get_flatten_out = keras.backend.function(\n",
        "    [model.layers[1].input],\n",
        "    [model.layers[1].output])\n",
        "get_drop_out = keras.backend.function(\n",
        "    [model.layers[2].input],\n",
        "    [model.layers[1].output])\n",
        "get_dense1_out = keras.backend.function(\n",
        "    [model.layers[3].input],\n",
        "    [model.layers[1].output])\n",
        "get_dense2_out = keras.backend.function(\n",
        "    [model.layers[4].input],\n",
        "    [model.layers[1].output])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFYslTIOUyUp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_layer_info(name, layer):\n",
        "    print(colored(\"Layer name: {0}\".format(name),\"blue\"))\n",
        "    layer_output = layer([x_test[0]])\n",
        "    print(\"Type {0} length of output layer {1} layer output {2}\".format(type(layer_output), len(layer_output), layer_output[0].shape))\n",
        "    print(\"The output is: \",layer_output)\n",
        "    return layer_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fskNMAsYUyUt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from termcolor import colored"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SoysS7HUyUw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fba197d8-3eb0-4b2e-b5ed-60a5e8939448"
      },
      "source": [
        "get_layer_info(\"Embedding layer\",get_embed_out)\n",
        "# get_layer_info(\"Flatten layer\",get_flatten_out)\n",
        "get_layer_info(\"Dropout layer\",get_drop_out)\n",
        "# get_layer_info(\"Dense layer 1\",get_dense1_out)\n",
        "# get_layer_info(\"Dense layer 2\",get_dense2_out)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34mLayer name: Embedding layer\u001b[0m\n",
            "Type <class 'list'> length of output layer 1 layer output (1, 600)\n",
            "The output is:  [array([[ 0.00224782,  0.00373507,  0.00224782,  0.00373507,  0.00224782,\n",
            "         0.00373507,  0.00224782,  0.00373507,  0.00224782,  0.00373507,\n",
            "         0.00224782,  0.00373507,  0.00224782,  0.00373507,  0.00224782,\n",
            "         0.00373507,  0.00224782,  0.00373507,  0.00224782,  0.00373507,\n",
            "         0.00224782,  0.00373507,  0.00224782,  0.00373507,  0.00224782,\n",
            "         0.00373507,  0.00224782,  0.00373507,  0.00224782,  0.00373507,\n",
            "         0.00224782,  0.00373507,  0.00224782,  0.00373507,  0.00224782,\n",
            "         0.00373507,  0.00224782,  0.00373507,  0.00224782,  0.00373507,\n",
            "         0.00224782,  0.00373507,  0.00224782,  0.00373507,  0.00224782,\n",
            "         0.00373507,  0.00224782,  0.00373507,  0.00224782,  0.00373507,\n",
            "         0.00224782,  0.00373507,  0.00224782,  0.00373507,  0.00224782,\n",
            "         0.00373507,  0.00224782,  0.00373507,  0.00224782,  0.00373507,\n",
            "         0.00224782,  0.00373507,  0.00224782,  0.00373507,  0.00224782,\n",
            "         0.00373507,  0.00224782,  0.00373507,  0.00224782,  0.00373507,\n",
            "         0.00224782,  0.00373507,  0.00224782,  0.00373507,  0.00224782,\n",
            "         0.00373507,  0.00224782,  0.00373507,  0.00224782,  0.00373507,\n",
            "         0.00224782,  0.00373507,  0.00224782,  0.00373507,  0.00224782,\n",
            "         0.00373507,  0.00224782,  0.00373507,  0.00224782,  0.00373507,\n",
            "         0.00224782,  0.00373507,  0.00224782,  0.00373507,  0.00224782,\n",
            "         0.00373507,  0.00224782,  0.00373507,  0.00224782,  0.00373507,\n",
            "         0.00224782,  0.00373507,  0.00224782,  0.00373507,  0.00224782,\n",
            "         0.00373507,  0.00224782,  0.00373507,  0.00224782,  0.00373507,\n",
            "         0.00224782,  0.00373507,  0.00224782,  0.00373507,  0.00224782,\n",
            "         0.00373507,  0.00224782,  0.00373507,  0.00224782,  0.00373507,\n",
            "         0.00224782,  0.00373507,  0.00224782,  0.00373507,  0.00224782,\n",
            "         0.00373507,  0.00224782,  0.00373507,  0.00224782,  0.00373507,\n",
            "         0.00224782,  0.00373507,  0.00224782,  0.00373507,  0.00224782,\n",
            "         0.00373507,  0.00224782,  0.00373507,  0.00224782,  0.00373507,\n",
            "         0.00224782,  0.00373507,  0.00224782,  0.00373507,  0.00224782,\n",
            "         0.00373507,  0.00224782,  0.00373507,  0.00224782,  0.00373507,\n",
            "         0.00224782,  0.00373507,  0.00224782,  0.00373507,  0.00224782,\n",
            "         0.00373507,  0.00224782,  0.00373507,  0.00224782,  0.00373507,\n",
            "         0.00224782,  0.00373507,  0.00224782,  0.00373507, -0.00325784,\n",
            "        -0.01535294,  0.00124715, -0.01465286, -0.00995639,  0.01347676,\n",
            "         0.02641151, -0.00874582,  0.03145523, -0.03078616, -0.23392156,\n",
            "         0.26370472,  0.0732412 , -0.06799402, -0.05733516,  0.06300869,\n",
            "         0.03506723, -0.03683818, -0.00568574, -0.00159853,  0.05283633,\n",
            "        -0.04102265, -0.13727176,  0.10455197,  0.00627752, -0.00678382,\n",
            "         0.07023516, -0.05121109,  0.00461437, -0.00209637, -0.02131634,\n",
            "         0.01976971,  0.02860971, -0.02808753, -0.02510075,  0.0089805 ,\n",
            "        -0.01963337,  0.02188558, -0.03286986,  0.03425741,  0.0490502 ,\n",
            "        -0.03277374,  0.03145523, -0.03078616,  0.06438797,  0.00957145,\n",
            "         0.00101097, -0.01062407,  0.03439534, -0.00601795,  0.05417969,\n",
            "        -0.04037325,  0.00160398, -0.01080041, -0.0131159 ,  0.00936471,\n",
            "         0.00452749,  0.01222369, -0.31241158,  0.24531128,  0.02861039,\n",
            "        -0.03719693, -0.01963337,  0.02188558, -0.04626626,  0.06114738,\n",
            "         0.00461437, -0.00209637, -0.00058313,  0.00491239,  0.00101097,\n",
            "        -0.01062407,  0.05894167, -0.05996144,  0.00160398, -0.01080041,\n",
            "        -0.04494739, -0.01057322, -0.02270721,  0.00979865, -0.00764236,\n",
            "         0.00398413,  0.00461437, -0.00209637, -0.00058313,  0.00491239,\n",
            "         0.04216946, -0.08102626, -0.04300632, -0.00657421, -0.00536561,\n",
            "         0.01533898, -0.00559917, -0.00763415,  0.00120538, -0.00148943,\n",
            "         0.00462625,  0.0033527 , -0.2517866 ,  0.28900525,  0.00461437,\n",
            "        -0.00209637, -0.00553217, -0.02964061,  0.03439534, -0.00601795,\n",
            "         0.02641151, -0.00874582, -0.00032389,  0.00466741, -0.05507465,\n",
            "         0.04053124,  0.08527292, -0.12704392,  0.00529215, -0.00743965,\n",
            "         0.00124715, -0.01465286, -0.00995639,  0.01347676,  0.00461437,\n",
            "        -0.00209637, -0.08799765,  0.20155975, -0.07686057, -0.02211625,\n",
            "        -0.0999138 ,  0.03824224,  0.00461437, -0.00209637, -0.00995639,\n",
            "         0.01347676,  0.00638378, -0.04123285, -0.17983624,  0.17898563,\n",
            "        -0.01361402,  0.02934847,  0.02641151, -0.00874582,  0.03145523,\n",
            "        -0.03078616, -0.23392156,  0.26370472,  0.00120538, -0.00148943,\n",
            "         0.0236214 , -0.01558027,  0.00150765,  0.00500367,  0.00462625,\n",
            "         0.0033527 ,  0.02789099,  0.00644086,  0.00461437, -0.00209637,\n",
            "        -0.00995639,  0.01347676, -0.00536561,  0.01533898, -0.03893618,\n",
            "         0.09543694, -0.00536561,  0.01533898, -0.01361402,  0.02934847,\n",
            "         0.02641151, -0.00874582,  0.00643827,  0.039882  ,  0.00134232,\n",
            "         0.0043696 ,  0.00160398, -0.01080041, -0.01963337,  0.02188558,\n",
            "         0.03936534, -0.03226715, -0.04793135,  0.08532074, -0.01361402,\n",
            "         0.02934847,  0.01977079, -0.00878499, -0.06775038,  0.08990566,\n",
            "         0.01977079, -0.00878499,  0.00402839,  0.01659183, -0.01963337,\n",
            "         0.02188558,  0.00461437, -0.00209637, -0.12593496,  0.01655235,\n",
            "         0.07705913, -0.02741539,  0.02641151, -0.00874582, -0.31241158,\n",
            "         0.24531128,  0.00627752, -0.00678382, -0.26898044,  0.17285492,\n",
            "         0.00114711,  0.02076806,  0.00461437, -0.00209637, -0.03944939,\n",
            "        -0.02333766, -0.01361402,  0.02934847,  0.02641151, -0.00874582,\n",
            "         0.00120538, -0.00148943,  0.06818459, -0.0172069 , -0.01963337,\n",
            "         0.02188558, -0.03286986,  0.03425741,  0.00070374,  0.03755172,\n",
            "        -0.02526555,  0.03264306,  0.02860971, -0.02808753, -0.00708862,\n",
            "         0.00989908,  0.02796057, -0.0288414 , -0.03286986,  0.03425741,\n",
            "        -0.0323739 ,  0.13111642,  0.00114711,  0.02076806, -0.00032389,\n",
            "         0.00466741, -0.00995639,  0.01347676, -0.01361402,  0.02934847,\n",
            "        -0.03728893,  0.0285492 ,  0.01740312, -0.01678276,  0.02518641,\n",
            "        -0.03518111, -0.03604813,  0.04099192, -0.01963337,  0.02188558,\n",
            "         0.00124715, -0.01465286, -0.14586404,  0.17228746,  0.02641151,\n",
            "        -0.00874582, -0.06921417,  0.05603853,  0.00160398, -0.01080041,\n",
            "         0.01977079, -0.00878499,  0.00461437, -0.00209637,  0.01808353,\n",
            "         0.01667891,  0.02084221,  0.02483015, -0.05380708,  0.13757399,\n",
            "         0.00150765,  0.00500367, -0.02510075,  0.0089805 ,  0.00461437,\n",
            "        -0.00209637,  0.00160398, -0.01080041, -0.00093747,  0.00833199,\n",
            "         0.04606666, -0.09863202, -0.01963337,  0.02188558, -0.0395342 ,\n",
            "         0.01236331,  0.02860971, -0.02808753,  0.00638378, -0.04123285,\n",
            "         0.03145523, -0.03078616, -0.23392156,  0.26370472, -0.00231174,\n",
            "        -0.00650398, -0.00426113, -0.00988361, -0.06249846,  0.05906677,\n",
            "         0.01881929, -0.02297674, -0.00487541,  0.01736321, -0.00093747,\n",
            "         0.00833199,  0.00461437, -0.00209637,  0.00160398, -0.01080041,\n",
            "        -0.0812798 ,  0.0474997 ,  0.00462625,  0.0033527 , -0.0524061 ,\n",
            "         0.03134852,  0.02635554,  0.00685998,  0.00461437, -0.00209637,\n",
            "        -0.03761603,  0.03004869,  0.00150765,  0.00500367, -0.00916692,\n",
            "         0.01316338, -0.01518357, -0.01317351, -0.02519087, -0.00058924,\n",
            "         0.01670491, -0.00913511, -0.00867459, -0.01733007, -0.00426113,\n",
            "        -0.00988361,  0.01676808, -0.03877643, -0.00032389,  0.00466741,\n",
            "         0.01269545,  0.03115493,  0.30562875, -0.22169387,  0.00134232,\n",
            "         0.0043696 ,  0.00461437, -0.00209637,  0.04888548, -0.09002639,\n",
            "        -0.00995639,  0.01347676, -0.00129523,  0.01115033, -0.05030965,\n",
            "        -0.02657409, -0.00231174, -0.00650398, -0.00426113, -0.00988361,\n",
            "        -0.31241158,  0.24531128, -0.01963337,  0.02188558,  0.02501095,\n",
            "        -0.06339408, -0.00285399, -0.02323633, -0.02515317,  0.08390235,\n",
            "         0.00134232,  0.0043696 , -0.02526555,  0.03264306,  0.02860971,\n",
            "        -0.02808753,  0.01740312, -0.01678276,  0.00727476,  0.00951457,\n",
            "        -0.00519015, -0.0075057 , -0.03286986,  0.03425741, -0.0524061 ,\n",
            "         0.03134852,  0.00461437, -0.00209637,  0.04888548, -0.09002639,\n",
            "        -0.00568574, -0.00159853,  0.02641151, -0.00874582,  0.00120538,\n",
            "        -0.00148943, -0.09135612,  0.15423957,  0.02635554,  0.00685998,\n",
            "        -0.01361402,  0.02934847,  0.02641151, -0.00874582, -0.07331683,\n",
            "         0.06617024, -0.01963337,  0.02188558,  0.02641151, -0.00874582,\n",
            "        -0.00496057, -0.05574311, -0.02803045,  0.05412117,  0.01542196,\n",
            "         0.0103205 , -0.02519087, -0.00058924,  0.00150765,  0.00500367,\n",
            "         0.02641151, -0.00874582, -0.2656908 ,  0.16833016,  0.00529215,\n",
            "        -0.00743965, -0.03925246,  0.05493205, -0.02519087, -0.00058924]],\n",
            "      dtype=float32)]\n",
            "\u001b[34mLayer name: Dropout layer\u001b[0m\n",
            "Type <class 'list'> length of output layer 1 layer output (300,)\n",
            "The output is:  [array([0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
            "       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
            "       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
            "       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
            "       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
            "       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
            "       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
            "       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
            "       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
            "       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
            "       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
            "       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
            "       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
            "       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 1.000e+00, 1.400e+01,\n",
            "       2.200e+01, 1.600e+01, 4.300e+01, 5.300e+02, 9.730e+02, 1.622e+03,\n",
            "       1.385e+03, 6.500e+01, 4.580e+02, 4.468e+03, 6.600e+01, 3.941e+03,\n",
            "       4.000e+00, 1.730e+02, 3.600e+01, 2.560e+02, 5.000e+00, 2.500e+01,\n",
            "       1.000e+02, 4.300e+01, 8.380e+02, 1.120e+02, 5.000e+01, 6.700e+02,\n",
            "       2.000e+00, 9.000e+00, 3.500e+01, 4.800e+02, 2.840e+02, 5.000e+00,\n",
            "       1.500e+02, 4.000e+00, 1.720e+02, 1.120e+02, 1.670e+02, 2.000e+00,\n",
            "       3.360e+02, 3.850e+02, 3.900e+01, 4.000e+00, 1.720e+02, 4.536e+03,\n",
            "       1.111e+03, 1.700e+01, 5.460e+02, 3.800e+01, 1.300e+01, 4.470e+02,\n",
            "       4.000e+00, 1.920e+02, 5.000e+01, 1.600e+01, 6.000e+00, 1.470e+02,\n",
            "       2.025e+03, 1.900e+01, 1.400e+01, 2.200e+01, 4.000e+00, 1.920e+03,\n",
            "       4.613e+03, 4.690e+02, 4.000e+00, 2.200e+01, 7.100e+01, 8.700e+01,\n",
            "       1.200e+01, 1.600e+01, 4.300e+01, 5.300e+02, 3.800e+01, 7.600e+01,\n",
            "       1.500e+01, 1.300e+01, 1.247e+03, 4.000e+00, 2.200e+01, 1.700e+01,\n",
            "       5.150e+02, 1.700e+01, 1.200e+01, 1.600e+01, 6.260e+02, 1.800e+01,\n",
            "       2.000e+00, 5.000e+00, 6.200e+01, 3.860e+02, 1.200e+01, 8.000e+00,\n",
            "       3.160e+02, 8.000e+00, 1.060e+02, 5.000e+00, 4.000e+00, 2.223e+03,\n",
            "       5.244e+03, 1.600e+01, 4.800e+02, 6.600e+01, 3.785e+03, 3.300e+01,\n",
            "       4.000e+00, 1.300e+02, 1.200e+01, 1.600e+01, 3.800e+01, 6.190e+02,\n",
            "       5.000e+00, 2.500e+01, 1.240e+02, 5.100e+01, 3.600e+01, 1.350e+02,\n",
            "       4.800e+01, 2.500e+01, 1.415e+03, 3.300e+01, 6.000e+00, 2.200e+01,\n",
            "       1.200e+01, 2.150e+02, 2.800e+01, 7.700e+01, 5.200e+01, 5.000e+00,\n",
            "       1.400e+01, 4.070e+02, 1.600e+01, 8.200e+01, 2.000e+00, 8.000e+00,\n",
            "       4.000e+00, 1.070e+02, 1.170e+02, 5.952e+03, 1.500e+01, 2.560e+02,\n",
            "       4.000e+00, 2.000e+00, 7.000e+00, 3.766e+03, 5.000e+00, 7.230e+02,\n",
            "       3.600e+01, 7.100e+01, 4.300e+01, 5.300e+02, 4.760e+02, 2.600e+01,\n",
            "       4.000e+02, 3.170e+02, 4.600e+01, 7.000e+00, 4.000e+00, 2.000e+00,\n",
            "       1.029e+03, 1.300e+01, 1.040e+02, 8.800e+01, 4.000e+00, 3.810e+02,\n",
            "       1.500e+01, 2.970e+02, 9.800e+01, 3.200e+01, 2.071e+03, 5.600e+01,\n",
            "       2.600e+01, 1.410e+02, 6.000e+00, 1.940e+02, 7.486e+03, 1.800e+01,\n",
            "       4.000e+00, 2.260e+02, 2.200e+01, 2.100e+01, 1.340e+02, 4.760e+02,\n",
            "       2.600e+01, 4.800e+02, 5.000e+00, 1.440e+02, 3.000e+01, 5.535e+03,\n",
            "       1.800e+01, 5.100e+01, 3.600e+01, 2.800e+01, 2.240e+02, 9.200e+01,\n",
            "       2.500e+01, 1.040e+02, 4.000e+00, 2.260e+02, 6.500e+01, 1.600e+01,\n",
            "       3.800e+01, 1.334e+03, 8.800e+01, 1.200e+01, 1.600e+01, 2.830e+02,\n",
            "       5.000e+00, 1.600e+01, 4.472e+03, 1.130e+02, 1.030e+02, 3.200e+01,\n",
            "       1.500e+01, 1.600e+01, 5.345e+03, 1.900e+01, 1.780e+02, 3.200e+01],\n",
            "      dtype=float32)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
              "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
              "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
              "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
              "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
              "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
              "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
              "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
              "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
              "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
              "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
              "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
              "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
              "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 1.000e+00, 1.400e+01,\n",
              "        2.200e+01, 1.600e+01, 4.300e+01, 5.300e+02, 9.730e+02, 1.622e+03,\n",
              "        1.385e+03, 6.500e+01, 4.580e+02, 4.468e+03, 6.600e+01, 3.941e+03,\n",
              "        4.000e+00, 1.730e+02, 3.600e+01, 2.560e+02, 5.000e+00, 2.500e+01,\n",
              "        1.000e+02, 4.300e+01, 8.380e+02, 1.120e+02, 5.000e+01, 6.700e+02,\n",
              "        2.000e+00, 9.000e+00, 3.500e+01, 4.800e+02, 2.840e+02, 5.000e+00,\n",
              "        1.500e+02, 4.000e+00, 1.720e+02, 1.120e+02, 1.670e+02, 2.000e+00,\n",
              "        3.360e+02, 3.850e+02, 3.900e+01, 4.000e+00, 1.720e+02, 4.536e+03,\n",
              "        1.111e+03, 1.700e+01, 5.460e+02, 3.800e+01, 1.300e+01, 4.470e+02,\n",
              "        4.000e+00, 1.920e+02, 5.000e+01, 1.600e+01, 6.000e+00, 1.470e+02,\n",
              "        2.025e+03, 1.900e+01, 1.400e+01, 2.200e+01, 4.000e+00, 1.920e+03,\n",
              "        4.613e+03, 4.690e+02, 4.000e+00, 2.200e+01, 7.100e+01, 8.700e+01,\n",
              "        1.200e+01, 1.600e+01, 4.300e+01, 5.300e+02, 3.800e+01, 7.600e+01,\n",
              "        1.500e+01, 1.300e+01, 1.247e+03, 4.000e+00, 2.200e+01, 1.700e+01,\n",
              "        5.150e+02, 1.700e+01, 1.200e+01, 1.600e+01, 6.260e+02, 1.800e+01,\n",
              "        2.000e+00, 5.000e+00, 6.200e+01, 3.860e+02, 1.200e+01, 8.000e+00,\n",
              "        3.160e+02, 8.000e+00, 1.060e+02, 5.000e+00, 4.000e+00, 2.223e+03,\n",
              "        5.244e+03, 1.600e+01, 4.800e+02, 6.600e+01, 3.785e+03, 3.300e+01,\n",
              "        4.000e+00, 1.300e+02, 1.200e+01, 1.600e+01, 3.800e+01, 6.190e+02,\n",
              "        5.000e+00, 2.500e+01, 1.240e+02, 5.100e+01, 3.600e+01, 1.350e+02,\n",
              "        4.800e+01, 2.500e+01, 1.415e+03, 3.300e+01, 6.000e+00, 2.200e+01,\n",
              "        1.200e+01, 2.150e+02, 2.800e+01, 7.700e+01, 5.200e+01, 5.000e+00,\n",
              "        1.400e+01, 4.070e+02, 1.600e+01, 8.200e+01, 2.000e+00, 8.000e+00,\n",
              "        4.000e+00, 1.070e+02, 1.170e+02, 5.952e+03, 1.500e+01, 2.560e+02,\n",
              "        4.000e+00, 2.000e+00, 7.000e+00, 3.766e+03, 5.000e+00, 7.230e+02,\n",
              "        3.600e+01, 7.100e+01, 4.300e+01, 5.300e+02, 4.760e+02, 2.600e+01,\n",
              "        4.000e+02, 3.170e+02, 4.600e+01, 7.000e+00, 4.000e+00, 2.000e+00,\n",
              "        1.029e+03, 1.300e+01, 1.040e+02, 8.800e+01, 4.000e+00, 3.810e+02,\n",
              "        1.500e+01, 2.970e+02, 9.800e+01, 3.200e+01, 2.071e+03, 5.600e+01,\n",
              "        2.600e+01, 1.410e+02, 6.000e+00, 1.940e+02, 7.486e+03, 1.800e+01,\n",
              "        4.000e+00, 2.260e+02, 2.200e+01, 2.100e+01, 1.340e+02, 4.760e+02,\n",
              "        2.600e+01, 4.800e+02, 5.000e+00, 1.440e+02, 3.000e+01, 5.535e+03,\n",
              "        1.800e+01, 5.100e+01, 3.600e+01, 2.800e+01, 2.240e+02, 9.200e+01,\n",
              "        2.500e+01, 1.040e+02, 4.000e+00, 2.260e+02, 6.500e+01, 1.600e+01,\n",
              "        3.800e+01, 1.334e+03, 8.800e+01, 1.200e+01, 1.600e+01, 2.830e+02,\n",
              "        5.000e+00, 1.600e+01, 4.472e+03, 1.130e+02, 1.030e+02, 3.200e+01,\n",
              "        1.500e+01, 1.600e+01, 5.345e+03, 1.900e+01, 1.780e+02, 3.200e+01],\n",
              "       dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMVBjSvsUyUy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4839badc-3d37-49de-c255-38489482053b"
      },
      "source": [
        "get_embed_out = keras.backend.function(\n",
        "    [model.layers[0].input],\n",
        "    [model.layers[0].output])\n",
        "layer_output = get_embed_out([x_test[0]])\n",
        "print(type(layer_output), len(layer_output), layer_output[0].shape)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'> 1 (300, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qEREwutUyU0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "55674889-d690-48b1-ba21-afa6e95639fb"
      },
      "source": [
        "words = layer_output[0]\n",
        "# print(words)\n",
        "plt.scatter(words[:,0], words[:,1])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f1b0bc07978>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUY26jQDUyU2",
        "colab_type": "text"
      },
      "source": [
        "# Verifying custom review - live review from IMDb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjDGoKSjUyU3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "def verify_review(myreview):\n",
        "    #vectorizing the review by the pre-fitted tokenizer instance\n",
        "    review_vector = vectorize(myreview,300)\n",
        "\n",
        "    # print(review_vector)\n",
        "\n",
        "    review_vector=pad_sequences([review_vector],maxlen=maxlen)\n",
        "    # print('Result',model.predict(review_vector,batch_size=1,verbose = 2))\n",
        "    sentiment = model.predict(review_vector,batch_size=1,verbose = 2)[0]\n",
        "#     print('Sentiment:',sentiment)\n",
        "    if(sentiment[0] > 0.9):\n",
        "        print(colored(\"This review is Positive\",\"green\"))\n",
        "    else:\n",
        "        print(colored(\"This review is Negative\",\"red\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CInY_ZW2UyU6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "2831de5e-f87d-420a-9712-9fec374e28f4"
      },
      "source": [
        "#Verifying an existing review at index 34 which is a negative review\n",
        "myreview = 'is forced to pursue the killer  the hunt leads all the way to the desolate ice  of the  ocean where man and beast play out their final fatal battle against each other br br two things stand out in this film one is the haunting score by   perhaps the greatest composer of film music of all time his talents wasted on various  rate  during the 70s and 80s the other is the amazing widescreen photography of ted moore which makes the film consistently pleasing to the eye in every other department  killer whale is a shoddy film that does nothing to enhance the reputation of its talented cast and crew harris appears extremely ill throughout the film his hair  black rings around his eyes and skin  pale his performance lacks the usual   strikes a lot of sexy poses but fails to convince with her long  and ill informed explanations about the ways of  the rest of the actors are wasted in brief and undeveloped roles the most memorable of which sees bo derek getting her leg bitten off by the vengeful whale the plot is total nonsense from start to finish with such preposterous sequences as the whale deliberately starting a fire in the fishing village that  and destroys the local  although it\\'s credible to suppose that  are intelligent creatures with genuine emotions the idea that a whale could plot revenge against a single human  and carry it out so  is utterly absurd  killer whale is really one for  of the man vs beast cycle from the late 70s most will come away from the film shaking their heads in disbelief and  their teeth with despair'\n",
        "print(\"My review length\",len(myreview))\n",
        "\n",
        "verify_review(myreview)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "My review length 1547\n",
            "1/1 - 0s\n",
            "\u001b[31mThis review is Negative\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9Xq7JYmUyU8",
        "colab_type": "text"
      },
      "source": [
        "### Verifying a review of the movie Onward https://www.imdb.com/review/rw5572599/?ref_=tt_urv a movie with 9/10 rating"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7tUFjfZUyU9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "5ef218b6-26d6-4954-e8f6-dbc0f0eb0f63"
      },
      "source": [
        "myreview = 'WOW Pixar is really moving onward with creativity and originality While the story itself and plotting may suffer a few issues like predictibility at times amazing animation and stunning visuals along with beautifully designed characters and great chemistry beetween actors who voiced those characters perfectly make this movie great enjoyable and worth watching The way they\\'ve used a mixture of real life elements and fantasy elements from Dungeons and Dragons universe is also great and worth mentioning While at first look it doesn\\'t feel like a Pixar movie the more time you spend watching it you will get all feelings and heart you expect from your average Pixar movie Dan Scanlon did a great job this time'\n",
        "\n",
        "print(\"My review length\",len(myreview))\n",
        "\n",
        "verify_review(myreview)\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "My review length 711\n",
            "1/1 - 0s\n",
            "\u001b[32mThis review is Positive\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "L3CSVVPPeCzD",
        "colab": {}
      },
      "source": [
        "#### predicting correctly as <font color='green'>Positive</font> review"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqwumeyMUyVA",
        "colab_type": "text"
      },
      "source": [
        "### Verifying a review of the movie Dod eat Dog https://www.imdb.com/review/rw3579490/?ref_=tt_urv . a movie with 1/10 rating"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TxNDNhrseCzA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "589312ed-9611-4dab-a4bf-3eda01848d36"
      },
      "source": [
        "myreview = 'I am a fan of Nicholas Cage who believes that his movies are just below the top grade but enjoyable at most times I read the storyline in IMDb and was seriously looking forward to have a good time Boy i was wrong There was no story no thrills but cheap gun shooting action I went all the way to write a review as i believe that this review could save someone their 90 minutes By the way this is only my 3rd review ever in the last 8 years the other 2 being positives and this one for the sheer disappointment i had with the movie Pls avoid this movie unless you are a blood thirsty movie lover'\n",
        "\n",
        "verify_review(myreview)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 - 0s\n",
            "\u001b[31mThis review is Negative\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0AqOnLa2eCzH",
        "colab": {}
      },
      "source": [
        "#### Predicting correctly as <font color='red'>Negative</font> review"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}